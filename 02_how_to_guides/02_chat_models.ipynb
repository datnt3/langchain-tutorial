{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddb78d8e",
   "metadata": {},
   "source": [
    "# 1. How to init any model in one line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2512897",
   "metadata": {},
   "source": [
    "## Basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b75bd4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini: I do not have a name. I am a large language model, trained by Google.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "gemini = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\", temperature=0)\n",
    "\n",
    "print(\"Gemini: \" + gemini.invoke(\"what's your name?\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b154a1",
   "metadata": {},
   "source": [
    "##  Inferring model provider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d92e55",
   "metadata": {},
   "source": [
    "## Creating a configurable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2edb63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I am a large language model, trained by Google.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--4087807a-4a3d-47e6-ba42-2af48ebfba90-0', usage_metadata={'input_tokens': 6, 'output_tokens': 150, 'total_tokens': 156, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 139}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configurable_model = init_chat_model(temperature=0)\n",
    "\n",
    "configurable_model.invoke(\n",
    "  \"what's your name\", config={\"configurable\": {\"model\": \"gemini-2.5-flash\", \"model_provider\": \"google_genai\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aaa0f7",
   "metadata": {},
   "source": [
    "### Configurable model with default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ca4c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I do not have a name. I am a large language model, trained by Google.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--45868077-2a0d-4ce5-b9d3-1695b9f724f9-0', usage_metadata={'input_tokens': 7, 'output_tokens': 53, 'total_tokens': 60, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 35}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_llm = init_chat_model(\n",
    "  model=\"gemini-2.5-flash\",\n",
    "  model_provider=\"google_genai\",\n",
    "  temperature=0,\n",
    "  configurable_fields=(\"model\", \"model_provider\", \"temperature\", \"max_tokens\"),\n",
    "  config_prefix=\"first\"\n",
    ")\n",
    "\n",
    "first_llm.invoke(\"what's your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6a797ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I do not have a name. I am a large language model, trained by Google.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': []}, id='run--adccc4b4-f186-414f-8672-734d158d1e5f-0', usage_metadata={'input_tokens': 6, 'output_tokens': 18, 'total_tokens': 24, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_llm.invoke(\n",
    "  \"what's your name\",\n",
    "  config={\n",
    "    \"configurable\": {\n",
    "      \"first_model\": \"gemini-2.5-flash-lite\",\n",
    "      \"first_temperature\": 0.8,\n",
    "      \"first_max_tokens:\": 100\n",
    "    }\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd19981",
   "metadata": {},
   "source": [
    "### Using a configurable model declaratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b4e14b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'GetPopulation',\n",
       "  'args': {'location': 'Los Angeles, CA'},\n",
       "  'id': 'd2ccb0a3-193b-45bf-9fea-40b26b41ad64',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'GetPopulation',\n",
       "  'args': {'location': 'New York, NY'},\n",
       "  'id': '6298c11f-9450-4aa9-a175-98d022dad284',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class GetWeather(BaseModel):\n",
    "   \"\"\"Get the current weather in a given location\"\"\"\n",
    "   location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n",
    "\n",
    "class GetPopulation(BaseModel):\n",
    "  \"\"\"Get the current population in a given location\"\"\"\n",
    "  location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n",
    "\n",
    "llm = init_chat_model(temperature=0)\n",
    "llm_with_tools = llm.bind_tools([GetWeather, GetPopulation])\n",
    "\n",
    "llm_with_tools.invoke(\n",
    "  \"what's bigger in 2024 LA or NYC\", config={\"configurable\": {\"model\": \"gemini-2.5-flash\", \"model_provider\": \"google_genai\"}}\n",
    ").tool_calls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
